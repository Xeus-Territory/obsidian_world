---
title: Awesome AWS Cloud
tags:
  - cheatsheet
  - helpful
  - cloud-services
  - aws
  - awesome
---
# Which reason do you concern AWS ?

![[thumbnail-aws.png]]

>[!quote]
>The big reason why i choose AWS about unique idea of maintainer and developer from AWS company put inside their services. They give me other perspective to create, control and manage service, and that is creating the difference between `aws` and `azure`. Especially, this cloud have some strange service and practice with it help me have more knowledge, and that why I concern to choose `AWS` and one more thing huge community stand behind will help you resolve any problems, for sure.
>
>If I concern about `aws` and `azure`, I will choose one of them depend on what I need to do. About trying to operate service like web dynamic - static, DB and container app, I will choose `azure`, and in another task, if I want to practice with secrets management, simple storage as S3, Queue message, ... I will choose `aws` for alternative

You can figure what you need to do for start with `aws` via some website and article

## Architecture

- [AWS Architecture Blog](https://aws.amazon.com/blogs/architecture/) ðŸŒŸ **(Recommended)**
- [AWS Architecture Center](https://aws.amazon.com/architecture/)
- [AWS Decision Guides](https://aws.amazon.com/getting-started/decision-guides/)
- [AWS Solutions Library](https://aws.amazon.com/solutions/ "AWS Solutions Library Homepage") ðŸŒŸ **(Recommended)**
- [AWS Prescriptive Guidance](https://aws.amazon.com/prescriptive-guidance/)
- [AWS Whitepapers & Guides](https://aws.amazon.com/whitepapers/)
## Community

- [AWS Blog](https://aws.amazon.com/blogs)
- [AWS Training](https://www.aws.training/)
## General

- [AWS Create Account Guide](https://docs.aws.amazon.com/accounts/latest/reference/manage-acct-creating.html)
- [AWS Documentation](https://docs.aws.amazon.com/)
- [AWS General Reference](https://docs.aws.amazon.com/general/latest/gr/Welcome.html)
- [AWS CLI - Configure the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html)
- [AWS CLI - Installation Guide](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html) 
## Utilities

- [AWS CLI - Command Guide](https://awscli.amazonaws.com/v2/documentation/api/latest/index.html)
- [AWS IAM Actions - Generator](https://www.awsiamactions.io/?r=0)
- [AWS Price Calculator](https://calculator.aws/#/)

You can manage `aws` as organization via the tree and sub-organization inside root account

![[aws-org-structure.png]]

Therefore enjoying what you need, inside each article will share about how you CLI, cheatsheet, collection of useful article around `aws` 

Externally, In `AWS` , I will share about some others topic, such as 

- **Services**
- **Certificates**
- **AWS Best Practice**
# Awesome AWS Repositories

## Organization

- [Github - Amazon Web Services](https://github.com/aws) - AWS Opensource Community ðŸŒŸ **(Recommended)**
- [Github - AWS Labs](https://github.com/awslabs) - AWS Labs ðŸŒŸ **(Recommended)**
- [Github - AWS Observability](https://github.com/aws-observability) - AWS Observability Setup
- [Github - AWS Samples](https://github.com/aws-samples) - AWS Samples Community
## Pages

- [Compose-X Labs](https://labs.compose-x.io/#): Aims to show-case Compose-X projects to deploy on AWS ECS
## Repository

- [all_aws_managed_policies](https://gist.github.com/gene1wood/55b358748be3c314f956): A list of all AWS managed policies and they're policy documents as well as a short script to generate the list
- [awesome-aws](https://github.com/donnemartin/awesome-aws) - A curated list of awesome Amazon Web Services (AWS) libraries, open source repos, guides, blogs, and other resources. ðŸŒŸ **(Recommended)**
- [grafana-aws-cloudwatch-dashboards](https://github.com/monitoringartist/grafana-aws-cloudwatch-dashboards): 40+ Grafana dashboards for AWS CloudWatch metrics
- [my-arsenal-of-aws-security-tools](https://github.com/toniblyx/my-arsenal-of-aws-security-tools): List of open source tools for AWS security: defensive, offensive, auditing, DFIR, etc.
## Tools

- [Serverless Better Credentials](https://www.serverless.com/plugins/serverless-better-credentials#serverless-better-credentials): Plugin replaces the existing AWS credential resolution mechanism, support SSO (Single Sign On)
# Blogs, Articles and Videos

## Articles

- [CloudZero - AWS NAT Gateway Pricing: Simple Strategies To Limit Costs](https://www.cloudzero.com/blog/reduce-nat-gateway-costs/)
- [PacketFabric - A Deep Dive into NAT Gateway Alternatives](https://packetfabric.com/blog/a-deep-dive-into-nat-gateway-alternatives)
- [Medium - 18 AWS Lambda Microstacks](https://awstip.com/18-aws-lambda-microstacks-bb20776601c0)
- [Medium - 14 AWS Security Microstacks](https://medium.com/@csjcode/14-aws-security-microstacks-95d120d57089)
- [Medium - 7 Effective Ways to Automate Cloud Infrastructure Auditing with AWS CloudTrail and AWS Config](https://aws.plainenglish.io/7-effective-ways-to-automate-cloud-infrastructure-auditing-with-aws-cloudtrail-and-aws-config-39d983f43d30)
- [AWS Docs - Configuring IAM Identity Center authentication with the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-sso.html)
- [Medium - 10 Little-Known AWS Services That Could Supercharge Your Cloud Strategy in 2025](https://medium.com/aws-in-plain-english/10-little-known-aws-services-that-could-supercharge-your-cloud-strategy-in-2025-7293912ee28d)
- [Medium - AWS Console-to-Code Now Generally Available](https://medium.com/@TechStoryLines/aws-console-to-code-now-generally-available-f0f63490ac9b)
- [AWS Docs - Understanding Lambda function scaling](https://docs.aws.amazon.com/lambda/latest/dg/lambda-concurrency.html)
- [AWS Blogs - 7 AWSome ways to use AWS Chatbot](https://aws.amazon.com/blogs/mt/7-awsome-ways-to-use-aws-chatbot/)
- [Medium - Full-stack Observability and Monitoring on AWS](https://kevinkiruri.medium.com/observability-and-monitoring-on-aws-42628f13b569)
- [Linkedin - ISO 27001 Compliance in AWS](https://www.linkedin.com/pulse/iso-27001-compliance-aws-valentin-komarovskiy-mba-ketke)
## Blogs

- [Medium - AWS in Plain English](https://aws.plainenglish.io/): New AWS, Cloud, and DevOps content every day. ðŸŒŸ **(Recommended)**
- [Medium - AWStip](https://awstip.com/): Community of passionate AWS builders. ðŸŒŸ **(Recommended)**
- [Medium - Chris St. John](https://medium.com/@csjcode)
## Development & Implementation

- [Medium - ECS (Fargate) with ALB Deployment Using Terraform â€” Part 3](https://medium.com/the-cloud-journal/ecs-fargate-with-alb-deployment-using-terraform-part-3-eb52309fdd8f) ðŸŒŸ **(Recommended)**
- [Medium - Creating SSL Certificates using AWS Certificate Manager (ACM)](https://medium.com/@sonynwoye/creating-ssl-certificates-using-aws-certificate-manager-acm-1c359e70ce4d)
- [AWS Blogs - AWS Multi-Account Security Reference Architecture](https://medium.com/squareops/aws-multi-account-security-reference-architecture-ac3c31f5e1f9)
- [AWS Docs - Configuring and managing a Multi-AZ deployment for Amazon RDS](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html)
- [AWS Docs - Profiling Amazon DocumentDB operations](https://docs.aws.amazon.com/documentdb/latest/developerguide/profiling.html)
- [AWS Blogs - Viewing Amazon CloudWatch metrics with Amazon Managed Service for Prometheus and Amazon Managed Grafana](https://aws.amazon.com/blogs/mt/viewing-amazon-cloudwatch-metrics-with-amazon-managed-service-for-prometheus-and-amazon-managed-grafana/)
- [AWS Blogs - Monitoring metrics and setting up alarms on your Amazon DocumentDB (with MongoDB compatibility) clusters](https://aws.amazon.com/blogs/database/monitoring-metrics-and-setting-up-alarms-on-your-amazon-documentdb-with-mongodb-compatibility-clusters/)
## Troubleshoot

- [AWS re:Post - Getting an Access Denied error message when I upload files to my Amazon S3 bucket](https://repost.aws/knowledge-center/s3-access-denied-error-kms)
- [AWS - Troubleshoot access denied (403 Forbidden) errors in Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/troubleshoot-403-errors.html#access-denied-message-examples)
## Videos

- [Youtube  - Amazon S3 - Static Website Hosting with Custom Domain and TLS](https://www.youtube.com/watch?v=X9cdkqBgLbs&ab_channel=BryanKrausen)
# AWS CLI

>[!question]
>You need to export some configuration before you can use `awscli`, such as
>- AWS_ACCESS_KEY_ID (Obligatory)
>- AWS_SECRET_ACCESS_KEY (Obligatory)
>- AWS_SESSION_TOKEN (If you have)
>- AWS_DEFAULT_REGION (Obligatory)
## S3

>[!warning]
>With `s3` some situation i set it upÂ `--endpoint-url`Â it mean i useÂ `localstack`Â for virtualizationÂ `aws`Â cloud on my machine, so keep mind and skip the flag if you want to applied to your `aws` cloud

### Create the bucket

```bash
aws --endpoint-url=http://localhost:4566 s3api create-bucket --bucket sample-bucket
```

### List the object in the bucket

```bash
aws --endpoint-url=http://localhost:4566 s3 ls s3://sample-bucket/
```

### Upload the object from directory to bucket, with single file or multiple files

```bash
# Upload only one file or dir
aws --endpoint-url=http://localhost:4566 s3 cp file|dir s3://sample-bucket

# Upload multiple
aws --endpoint-url=http://localhost:4566 s3 cp file|dir s3://sample-bucket --recursive
```

### Read contents inside bucket

```bash
aws --endpoint-url=http://localhost:4566 s3 cp s3://sample-bucket/file -
```

### Delete a huge bucket with versioning enable

Discovery more about issue at [StackOverFlow - How do I delete a versioned bucket in AWS S3 using the CLI?](https://stackoverflow.com/questions/29809105/how-do-i-delete-a-versioned-bucket-in-aws-s3-using-the-cli)

```bash
# Use command for deleting
aws s3api delete-objects \
    --bucket name-bucket \
    --delete "$(aws s3api list-object-versions \
    --bucket "name-bucket" \
    --output=json --max-items 500 --query='{Objects: Versions[].{Key:Key,VersionId:VersionId}}')"
```

```bash
# Use loop for deleting
NB_OBJECTS=$(aws s3api list-object-versions --bucket ${buckettoempty} --query='length(Versions[*] || `[]` )' | awk '{ print $1 }')
echo "      '${NB_OBJECTS}' objects to remove"
if [[ "$NB_OBJECTS" != "0" ]]; then
  start=$SECONDS
  while [[ $NB_OBJECTS -gt 0 ]]
  do
    aws s3api delete-objects --bucket ${buckettoempty} --delete "$(aws s3api list-object-versions --bucket ${buckettoempty} --max-items 500 --query='{Objects: Versions[0:500].{Key:Key,VersionId:VersionId}}')" --query 'length(Deleted[*] || `[]` )' > /dev/null
    NB_OBJECTS=$((NB_OBJECTS  > 500 ? NB_OBJECTS - 500 : 0))
    echo "      Removed batch of Objects... Remaining : $NB_OBJECTS ($(( SECONDS - start ))s)"
  done
fi

NB_OBJECTS=$(aws s3api list-object-versions --bucket ${buckettoempty} --query='length(DeleteMarkers[*] || `[]` )' | awk '{ print $1 }')
echo "      '${NB_OBJECTS}' markers to remove"
if [[ "$NB_OBJECTS" != "0" ]]; then
  start=$SECONDS
  while [[ $NB_OBJECTS -gt 0 ]]
  do
    aws s3api delete-objects --bucket ${buckettoempty} --delete "$(aws s3api list-object-versions --bucket ${buckettoempty} --max-items 500 --query='{Objects: DeleteMarkers[0:500].{Key:Key,VersionId:VersionId}}')" --query 'length(Deleted[*] || `[]` )' > /dev/null
    NB_OBJECTS=$((NB_OBJECTS  > 500 ? NB_OBJECTS - 500 : 0))
    echo "      Removed batch of Markers... Remaining : $NB_OBJECTS (took $(( SECONDS - start ))s)"
  done
fi
```
## STS

### Get caller identity to detect `whoami` or `role`

```bash
aws sts get-caller-identity
```

### Assume role with web-identity

```bash
aws sts assume-role-with-web-identity \
--role-arn arn:aws:iam::xxxxx:role/rolename \
--role-session-name <what-ever-you-want> \
--web-identity-token $TOKEN # mostly token is JWT Format
```

### Assume role with one-command

Documentation: [StackOverFlow - AWS sts assume role in one command](https://stackoverflow.com/questions/63241009/aws-sts-assume-role-in-one-command)

```bash
export $(printf "AWS_ACCESS_KEY_ID=%s AWS_SECRET_ACCESS_KEY=%s AWS_SESSION_TOKEN=%s" \
$(aws sts assume-role \
--role-arn arn:aws:iam::123456789012:role/MyAssumedRole \
--role-session-name MySessionName \
--query "Credentials.[AccessKeyId,SecretAccessKey,SessionToken]" \
--output text))
```
## ECS

### List task inside ECS Cluster

```bash
aws ecs list-tasks --cluster <name-cluster>
```

### Execution command

>[!warning]
>In this part you need to confirm two thing to install inside cluster and your machine

In your machine, need to install `session-manager-plugin`. Use `curl` command to download

```bash
curl "https://s3.amazonaws.com/session-manager-downloads/plugin/latest/ubuntu_64bit/session-manager-plugin.deb" -o "session-manager-plugin.deb"
```

 In your task, you need enable feature execute-command if not

```bash
aws ecs update-service \
--cluster <cluster-name> --service <service-name> \
--enable-execute-command --force-new-deployment
```

And now if you confirm two thing about you can use execution to inject something inside container

```bash
# Exam: task-arn-specific = d274e386xxxxxxxxxxx2fd28b5ac
aws ecs execute-command --cluster <cluster-name> \
--container <name-container> --interactive --task <task-arn-specific> \
--command <your/command>
```

## ECR

### Get login password of your ECR

```bash
aws ecr get-login-password
```

### Login to your ECR

```bash
aws ecr get-login-password | crane auth login -u AWS --password-stdin <url-ecr>
```

## EKS

### Get token of cluster

```bash
aws eks get-token --cluster-name <name>
```

### Create kubeconfig file automatically

```bash
aws eks update-kubeconfig --region region-code --name my-cluster
```
## SQS

###  Retrieve message from queue

```bash
aws sqs receive-message \
--queue-url <sqs-url> \
--attribute-names All --message-attribute-names All \
--max-number-of-messages 10
```

## SNS

### Subscribe `webhook` with SNS

Use can use two platform to generate endpoint

- [Beeceptor](https://beeceptor.com/) : API Mocking
- [Webhook.site](https://webhook.site/) : Generates free, unique URLs and e-mail addresses and lets you see everything thatâ€™s sent there instantly. (Usage: Steal cookies, bypass authorized, â€¦)

```bash
aws sns subscribe \
    --topic-arn <topic-arn> \
    --protocol https \
    --notification-endpoint <endpoint>
```

## Cognito-identity

### Get Identity

```bash
aws cognito-identity get-id --identity-pool-id <identity-pool-id>
```

### Get Credential

```bash
aws cognito-identity get-credentials-for-identity --identity-id <identity-from-get-identity>
```

### Get Open ID Token

>[!note]
>Use when you receive `open-id` token to retrieve the credential to access AWS

```bash
aws cognito-identity get-open-id-token --identity-id <identity-from-get-identity>
```

## Configure

### Set credential for profile

```bash
aws configure --profile <profile-name>
```

And easily you can temporarily switch profiles with export to environment variable

```bash
# V1
export AWS_DEFAULT_PROFILE=<profile-name>
# V2
export AWS_PROFILE=<profile-name>
```

# Cheatsheet and Script

## S3

### Retrieve file data from S3

>[!summary]
>This script will be helped you for retrieving the file from your S3 bucket

```bash
#!/bin/bash

bucket="$1"
amzFile="$2"
outputFile="$3"
resource="/${bucket}/${amzFile}"
contentType="application/x-compressed-tar"
dateValue=$(date -R)
stringToSign="GET\n\n${contentType}\n${dateValue}\n${resource}"
AWS_ACCESS_KEY_ID="$4"
AWS_SECRET_ACCESS_KEY="$5"
signature=$(echo -en "${stringToSign}" | openssl sha1 -hmac ${AWS_SECRET_ACCESS_KEY} -binary | base64)

echo -n "$(curl  -H "Host: ${bucket}.s3.amazonaws.com" \
     -H "Date: ${dateValue}" \
     -H "Content-Type: ${contentType}" \
     -H "Authorization: AWS ${AWS_ACCESS_KEY_ID}:${signature}" \
     https://${bucket}.s3.amazonaws.com/${amzFile} -o "$outputFile")"
```
### Upload file to S3

>[!summary]
>This script will help you upload a new file to S3 bucket

```bash
#!/bin/bash

file="FILEPATH"
bucket="BUCKET_NAME"
folder="FOLDER_IN_BUCKET"
resource="/${bucket}/${folder}/${file}"
contentType="text/plain"
dateValue=$(date -R)
s3Key="S3KEY"
s3Secret="S3SECRET"

# Check if the file exists on S3
httpResponseCode=$(curl -I -s -o /dev/null -w "%{http_code}" -X HEAD -H "Host: ${bucket}.s3.amazonaws.com" "https://${bucket}.s3.amazonaws.com/${folder}/${file}")

if [ $httpResponseCode -eq 200 ]; then
  # If the file exists, delete it
  deleteDateValue=$(date -R)
  deleteResource="/${bucket}/${folder}/${file}"
  deleteStringToSign="DELETE\n\n\n${deleteDateValue}\n${deleteResource}"
  deleteSignature=$(echo -en "${deleteStringToSign}" | openssl sha1 -hmac "${s3Secret}" -binary | base64)

  # Send the DELETE request
  curl -X DELETE -H "Host: ${bucket}.s3.amazonaws.com" -H "Date: ${deleteDateValue}" -H "Authorization: AWS ${s3Key}:${deleteSignature}" "https://${bucket}.s3.amazonaws.com/${folder}/${file}"
  echo ">>>>>>>>>>>>>>>>>>> An existing file was deleted successfully!"
fi

# Now, upload the new file
stringToSign="PUT\n\n${contentType}\n${dateValue}\n${resource}"
signature=$(echo -en "${stringToSign}" | openssl sha1 -hmac "${s3Secret}" -binary | base64)

# Send the PUT request to upload the new file
curl -L -X PUT -T "${file}" -H "Host: ${bucket}.s3.amazonaws.com" -H "Date: ${dateValue}" -H "Content-Type: ${contentType}" -H "Authorization: AWS ${s3Key}:${signature}" "https://${bucket}.s3.amazonaws.com/${folder}/${file}"
echo ">>>>>>>>>>>>>> A new file was uploaded successfully!"
```


