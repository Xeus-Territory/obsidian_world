---
title: "DueWeekly Tech: 24-02-2025 to 09-03-2025"
tags:
  - collections
  - tech
  - dueweeklytech
draft: "true"
---

![[meme-cache.png]]

# Data Engineer

[1. Airbyte - Data Pipeline vs. ETL: Optimize Data Flow (Beginner's Guide)](https://airbyte.com/data-engineering-resources/data-pipeline-vs-etl)

- The comparison btw Data pipeline and ETL with detail explaining and key differences, you can easier understand use case for using once of them
- Give you more information each data stage in progress for Data Pipeline and ETL

[2. Airbyte - What is Data Extraction? Data Extraction Tools and Techniques](https://airbyte.com/data-engineering-resources/data-extraction)

- Explain the theory of Data Extraction and list main stage of this progress
- Give you couple of methods and techniques related Data Extraction
- Comparison btw Data Extraction and Data Mining
- Challenge and how we can handle extraction for empowering business
- Tools and usage for applying ETL for Data Extraction, and learn how to automate that one
- Relate to best practices in Data Extraction
- In the end, you will have couple of example real world with applying Data Extraction progress

[3. Airbyte - What is Data Pipeline: Benefits, Types, & Examples](https://airbyte.com/data-engineering-resources/data-pipeline)

- Explain the theory of Data Pipeline with couple of benefits of them and what components inside data pipelines, such as Origin, Destination, Dataflow, Storage, Workflow and Monitoring
- List a couple of data pipeline styles with explaining
- Covey some example for relating what use-case should use data pipelines

[4. Medium - dbt in Production: Airflow with Kubernetes](https://medium.com/@dennis-sin/dbt-in-production-airflow-with-kubernetes-36db10d2a8f1)

- Learn about challenge when use DBT inside the scaling system, with many things problems can be occur, such as conflict package, managed airflow, ...
- They want to bring DBT with concept Airflow and Kubernetes, because they will use `KubernetesPodOperator` for scale up DBT and use this pod created new DBT for each task
- List about couples of tech debt need to solve when use this strategies for logging and save artifact

[5. Medium - Airflow: Why is nothing working?](https://medium.com/bluecore-engineering/airflow-why-is-nothing-working-f705eb6b7b04)

- We will learn about problem of Bluecore when setup airflow and use `SubDagOperators` to cause Deadlock for Data Pipeline with scale up `Celery` but not solving
- They try to explain why they configure wrong and what happen inside their system and give the solution for tackling problem. From step to simple disassemble, they know about the SubDagOperator mess up with executing child Dag and parrent Dag should wait before child completely and child dags not finish and cause deadlock.
- They replace with [new custom Operator](https://gist.github.com/JLDLaughlin/2e60fa47704a9f4536b837e62dc8b14e) for executing single task and anything worked

[6. Medium - We’re All Using Airflow Wrong and How to Fix It](https://medium.com/bluecore-engineering/were-all-using-airflow-wrong-and-how-to-fix-it-a56f14cb0753)

- List some challenge and problems when work with Airflow, such as Functional task with operator, hard to debug with Airflow Operator and architecture of dags when use worker for executing (Refresh installing progress anytime).
- For fix problem, they try to use `KubernetesOperator` for trigger creating new pod for multitasking in multiple different requirements and prevent conflict, with detailing evidence

[7. Youtube - Orchestrating Airbyte and dbt with Airflow](https://www.youtube.com/watch?v=rBsfUiHoNdc)

- Video is a tutorial which try to help you build Dag in Airflow used both technology Airbyte and DBT
- Write to use `DBT` in good way with use BashExecutor inside Airflow and we manage the ETL inside Airbyte
- But it's is use Docker and maybe different when you use it with Kubernetes

[8. Airflow - Best Practices of Airflow](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html)

[9. Medium - Top 10 Apache Airflow Best Practices for Data Engineers](https://medium.com/@Nelsonalfonso/top-10-apache-airflow-best-practices-for-data-engineers-f72de2b6175d)

[10. Airflow - Dynamic Task Mapping](https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/dynamic-task-mapping.html)
# Kubernetes

[1. GitGuardian - How to Handle Secrets in Helm](https://blog.gitguardian.com/how-to-handle-secrets-in-helm/)

- Article is a guideline to help you imagine how to integrate helm-secrets into deployments for protecting secrets variables with cross team used GitOps Strategies
- Use `helm-secrets` with `SOPS` for encrypting/decrypting in bidirection
- Use external operator in Kubenetes Cluster for automatically retrieves secrets from secret managers like AWS Secrets Manager, HashiCorp Vault, Google Secrets Manager, Azure Key Vault, etc.
- Relate to couple of method to protect secrets with Vault Operator and try to update pod with new secrets updating with [Reloader](https://github.com/stakater/Reloader?ref=blog.gitguardian.com)